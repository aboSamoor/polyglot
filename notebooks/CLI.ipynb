{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polyglot package offer a command line interface along with the library access.\n",
    "For each task in polyglot, there is a subcommand with specific options for that task.\n",
    "Common options are gathered under the main command `polyglot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: polyglot [-h] [--lang LANG] [--delimiter DELIMITER] [--workers WORKERS] [-l LOG] [--debug]\r\n",
      "                {detect,morph,tokenize,download,count,cat,ner,pos,transliteration,sentiment} ...\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --lang LANG           Language to be processed\r\n",
      "  --delimiter DELIMITER\r\n",
      "                        Delimiter that seperates documents, records or even sentences.\r\n",
      "  --workers WORKERS     Number of parallel processes.\r\n",
      "  -l LOG, --log LOG     log verbosity level\r\n",
      "  --debug               drop a debugger if an exception is raised.\r\n",
      "\r\n",
      "tools:\r\n",
      "  multilingual tools for all languages\r\n",
      "\r\n",
      "  {detect,morph,tokenize,download,count,cat,ner,pos,transliteration,sentiment}\r\n",
      "    detect              Detect the language(s) used in text.\r\n",
      "    tokenize            Tokenize text into sentences and words.\r\n",
      "    download            Download polyglot resources and models.\r\n",
      "    count               Count words frequency in a corpus.\r\n",
      "    cat                 Print the contents of the input file to the screen.\r\n",
      "    ner                 Named entity recognition chunking.\r\n",
      "    pos                 Part of Speech tagger.\r\n",
      "    transliteration     Rewriting the input in the target language script.\r\n",
      "    sentiment           Classify text to positive and negative polarity.\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that most of the operations are language specific.\n",
    "For example, tokenization rules and part of speech taggers differ between languages.\n",
    "Therefore, it is important that the lanaguage of the input is detected or given.\n",
    "The `--lang` option allows you to tell polyglot which language the input is written in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia posted a World Cup record total of 417 - 6 as they beat Afghanistan by 275 runs .\r\n",
      "David Warner hit 178 off 133 balls , Steve Smith scored 95 while Glenn Maxwell struck 88 in 39 deliveries in the Pool A encounter in Perth .\r\n",
      "Afghanistan were then dismissed for 142 , with Mitchell Johnson and Mitchell Starc taking six wickets between them .\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot --lang en tokenize --input testdata/cricket.txt | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the user did not supply the the language code, polyglot will peek ahead and read the first 1KB of data to detect the language used in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-03-15 17:06:45 INFO __main__.py: 276 Language English is detected while reading the first 1128 bytes.\r\n",
      "Australia posted a World Cup record total of 417 - 6 as they beat Afghanistan by 275 runs .\r\n",
      "David Warner hit 178 off 133 balls , Steve Smith scored 95 while Glenn Maxwell struck 88 in 39 deliveries in the Pool A encounter in Perth .\r\n",
      "Afghanistan were then dismissed for 142 , with Mitchell Johnson and Mitchell Starc taking six wickets between them .\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot tokenize --input testdata/cricket.txt | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polyglot will process the input contents line by line assuming that the lines are separated by \"`\\n`\".\n",
    "If the file is formatted differently, you can use the polyglot main command option `delimiter` to specify any string other than \"`\\n`\".\n",
    "\n",
    "You can pass text to the polyglot subcommands in several ways:\n",
    "\n",
    "- **Standard input**: This is, usually, useful for building processing pipelines.\n",
    "\n",
    "\n",
    "- **Text file**: The file contents will be processed line by line.\n",
    "\n",
    "\n",
    "- **Collection of text files**: Polyglot will iterate over the files one by one.\n",
    "If the polyglot main command option `workers` is activated, the execution will be parallelized and each file will be processed by a different process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will demonstrate how to use the polyglot main command options and the subcommand count to generate a count of the words appearing in a collection of text files.\n",
    "\n",
    "First, let us examine the subcommand `count` options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: polyglot count [-h] [--min-count MIN_COUNT | --most-freq MOST_FREQ] [--input [INPUT [INPUT ...]]]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --min-count MIN_COUNT\r\n",
      "                        Ignore all words that appear <= min_freq.\r\n",
      "  --most-freq MOST_FREQ\r\n",
      "                        Consider only the most frequent k words.\r\n",
      "  --input [INPUT [INPUT ...]]\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot count --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid long output, we will restrict the count to the words that appeared at least twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\t10\r\n",
      "the\t6\r\n",
      "by\t3\r\n",
      "and\t3\r\n",
      "of\t3\r\n",
      "Bermuda\t2\r\n",
      "West\t2\r\n",
      "Mitchell\t2\r\n",
      "South\t2\r\n",
      "Indies\t2\r\n",
      "against\t2\r\n",
      "beat\t2\r\n",
      "as\t2\r\n",
      "India\t2\r\n",
      "which\t2\r\n",
      "score\t2\r\n",
      "Afghanistan\t2\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot count --input testdata/cricket.txt --min-count 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the scenario where we have hundreds of files that contains words we want to count.\n",
    "Notice, that we can parallelize the process by passing a number higher than 1 to the polyglot main command option `workers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\t20\r\n",
      "the\t12\r\n",
      "of\t6\r\n",
      "by\t6\r\n",
      "and\t6\r\n",
      "West\t4\r\n",
      "Afghanistan\t4\r\n",
      "India\t4\r\n",
      "beat\t4\r\n",
      "which\t4\r\n",
      "Indies\t4\r\n",
      "Bermuda\t4\r\n",
      "as\t4\r\n",
      "South\t4\r\n",
      "Mitchell\t4\r\n",
      "against\t4\r\n",
      "score\t4\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot --log debug --workers 5 count --input testdata/cricket.txt testdata/cricket.txt --min-count 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous subcommand `count` assumed that the words are separted by spaces.\n",
    "Given that we never tokenized the text file, that may result in suboptimal word counting.\n",
    "Let us take a closer look at the tail of the word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ireland\t1\r\n",
      "surpassed\t1\r\n",
      "amount\t1\r\n",
      "equalled\t1\r\n",
      "a\t1\r\n",
      "The\t1\r\n",
      "413-5\t1\r\n",
      "Africa's\t1\r\n",
      "tournament\t1\r\n",
      "Johnson\t1\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot count --input testdata/cricket.txt | tail -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that words like \"2007.\" could have been considered two words \"2007\" and \".\" and the same for \"Africa's\".\n",
    "To fix this issue, we can use the polyglot subcommand tokenize to deal with these cases.\n",
    "We can stage the counting to happen after the tokenization using the stdin to build a simple pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\t10\r\n",
      "the\t6\r\n",
      ".\t6\r\n",
      "-\t5\r\n",
      ",\t4\r\n",
      "of\t3\r\n",
      "and\t3\r\n",
      "by\t3\r\n",
      "South\t2\r\n",
      "5\t2\r\n",
      "2007\t2\r\n",
      "Bermuda\t2\r\n",
      "which\t2\r\n",
      "score\t2\r\n",
      "against\t2\r\n",
      "Mitchell\t2\r\n",
      "as\t2\r\n",
      "West\t2\r\n",
      "India\t2\r\n",
      "beat\t2\r\n",
      "Afghanistan\t2\r\n",
      "Indies\t2\r\n"
     ]
    }
   ],
   "source": [
    "!polyglot --lang en tokenize --input testdata/cricket.txt | polyglot count --min-count 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, that the word \"2007\" started appearing in the words counts list."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
